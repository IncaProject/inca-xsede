
-------------------
Programming tasks
-------------------

[ 1. complete 3/20/07 ]
  - email notification for MDS tests and others

2. shade resources based on planned downtimes
  - Effort: medium
  - Waiting on availability of downtime data from Diana & Mike

[ 3. complete 3/6/07 ]
  - show which errors are in ticketing system (requested by Tony 10/30) 
  - manually add in same xml file as pkg wait status

4. a diff capability to see which tests are still failing from one week to the
next, which ones were resolved, and new tests that are failing (suggested by
shava to tony - 12/1/06)
   - Effort: medium
   - Add new query to depot and develop stylesheet

5. Historical graphs
   - E.g., for a test that is failing on a single resource, being able to view
     the history of pass/fail to whether it is happening often enough that it
     should be addressed or is just a fluke.  Also being able to view the
     different types of error messages that have occurred and when, for
     example, when you wanted to know whether that uberftp fail message 'file
     does not match original' had happened before. (suggested by shava to tony
     - 12/1/06)
   - E.g., for flaky gt4 services, being able to see a graph where you could
     use check boxes to select the pass/fail history to see how often a
     service is failing and one which resources.  Also example, being able to
     view how much more reliable the services are on resources which have
     deployed the patches, and so on. (suggested by shava to tony - 12/1/06)
    - Effort:  medium
    - First version can display text data
    - Second version can display graphing interface

6. integration with CTSS4
  - Effort: medium - hard
  - need to talk to JP & Lee in more detail

7.  Revive softenv key page from CTSS2 (requested by Jay Alameda)
  - Effort: easy
  - Just need to deploy reporter and develop stylesheet

8. run now button from web page for admins (requested by Doru)
   - Effort:  hard
   - part of proposal

9. add form for sys admins to input comments about errors (requested by Tony
10/30)
  - Timeframe:  hard
  - really same as knowledge base idea from proposal

10. tune the frequency of a test based on results -- i.e., if a test fails,
    start testing it more frequently (requested by Tony - 2/26)
    - Timeframe:  hard
    - Part of proposal - also tune based on impact of test on resource
    - need to figure out what Inca component would be responsible for checking
      results and then sending a schedule change

-------------------
Deployment tasks
-------------------
* change name of resources to that of group & use equivalent
